<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>tracking.js - face with camera</title>
  <link rel="stylesheet" href="assets/demo.css">

  <script src="../build/tracking-min.js"></script>
  <script src="../build/data/face-min.js"></script>
   <script src="../node_modules/dat.gui/build/dat.gui.min.js"></script>
  <script src="assets/stats.min.js"></script>
  <script src="../Tone.js/build/Tone.js"></script>
  <script src="../Tone.js/examples/scripts/StartAudioContext.js"></script>
	<script src="../Tone.js/examples/scripts/jquery.min.js"></script>
	<script src="../Tone.js/examples/scripts/draggabilly.js"></script>
	<script src="../Tone.js/examples/scripts/Interface.js"></script>
	<script src="https://tonejs.github.io/Logo/build/Logo.js"></script>

	<!-- <link rel="stylesheet" type="text/css" href="./style/examples.css"> -->
  <style>
  video, canvas {
    margin-left: 230px;
    margin-top: 120px;
    position: absolute;
  }
  </style>
</head>
<body>
  <div class="demo-title">
    <p><a href="http://trackingjs.com" target="_parent">tracking.js</a> Ôºç get user's webcam and detect faces</p>
  </div>

  <div class="demo-frame">
    <div class="demo-container">
      <video id="video" width="500" height="500" preload autoplay loop muted></video>
      <canvas id="canvas" width="500" height="500"></canvas>
    </div>
  </div>

  <script>
    // var osc = new Tone.Oscillator({
		// 	"frequency" : 440,
		// 	"volume" : -10
    // }).toMaster();
    // osc.start();
    window.onload = function() {
      var video = document.getElementById('video');
      var canvas = document.getElementById('canvas');
      var context = canvas.getContext('2d');
      var oldRect={};
      oldRect.x = 0;
      oldRect.y = 0;
      oldRect.width=0;
      oldRect.height=0;
      var osc = new Tone.Oscillator(240, "sine").toMaster();
           osc.start();
      var tracker = new tracking.ObjectTracker('face');
      tracker.setInitialScale(4);
      tracker.setStepSize(2);
      tracker.setEdgesDensity(0.1);

      tracking.track('#video', tracker, { camera: true });

      tracker.on('track', function(event) {
        context.clearRect(0, 0, canvas.width, canvas.height);

        event.data.forEach(function(rect) {
          context.strokeStyle = '#a64ceb';
          context.strokeRect(rect.x, rect.y, rect.width, rect.height);
          context.font = '11px Helvetica';
          context.fillStyle = "#fff";
          context.fillText('x: ' + rect.x + 'px', rect.x + rect.width + 5, rect.y + 11);
          context.fillText('y: ' + rect.y + 'px', rect.x + rect.width + 5, rect.y + 22);
          Tone.Master.volume.rampTo(Math.abs((rect.x -oldRect.x)%10 )*31, 0.1);
          // var osc = new Tone.Oscillator(rect.x-1004, "sine").toMaster();
          // osc.start();
          // var signal = new Tone.Signal(rect.x, "")
          console.log(Tone.Master.volume)
          console.log('rect.x and rect.y-----', rect.x, rect.y)
          oldRect = rect;
        });
      });

      var gui = new dat.GUI();
      gui.add(tracker, 'edgesDensity', 0.1, 0.5).step(0.01);
      gui.add(tracker, 'initialScale', 1.0, 10.0).step(0.1);
      gui.add(tracker, 'stepSize', 1, 5).step(0.1);
    };
  </script>

</body>
</html>
